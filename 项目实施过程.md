# 大语言模型部署测试及横向对比

## 1 项目简介


1. 登录并使用魔搭平台，关联阿里云账号来获得免费的CPU云计算资源；

2. 通过Jupyter Notebook进入相应的项目部署环境，完成模型的部署；

3. 针对2-3个不同的模型进行一些应用场景的测试，并开展不同模型之间的横向对比；



**本项目中横向对比的几个模型分别是：**

- [通义千问Qwen-7B-Chat](https://www.modelscope.cn/models/qwen/Qwen-7B-Chat/summary)

- [智谱ChatGLM3-6B](https://www.modelscope.cn/models/ZhipuAI/chatglm3-6b/summary)

- [百川2-7B-对话模型](https://www.modelscope.cn/models/baichuan-inc/Baichuan2-7B-Chat/summary)

 

**应用场景样例为：**

- 请说出以下两句话区别在哪里？ 1、冬天：能穿多少穿多少 2、夏天：能穿多少穿多少

- 请说出以下两句话区别在哪里？单身狗产生的原因有两个，一是谁都看不上，二是谁都看不上

- 他知道我知道你知道他不知道吗？ 这句话里，到底谁不知道

- 明明明明明白白白喜欢他，可她就是不说。 这句话里，明明和白白谁喜欢谁？

- 领导：你这是什么意思？ 小明：没什么意思。意思意思。 领导：你这就不够意思了。 小明：小意思，小意思。领导：你这人真有意思。 小明：其实也没有别的意思。 领导：那我就不好意思了。 小明：是我不好意思。请问：以上“意思”分别是什么意思。

## 2 配置流程

### 2.1 配置云服务器

在魔搭平台中登录并绑定阿里云账号，获得免费配套云计算资源，并启动CPU服务器

服务器预装镜像：ubuntu22.04-py311-torch2.3.1-1.26.0

### 2.2 环境配置

1. 使用 pip 命令安装依赖
    ```
    pip install-U pip setuptools wheel
    pip install \
     "intel-extension-for-transformers==1.4.2" \
     "neural-compressor==2.5" \
     "transformers==4.33.3" \
     "modelscope==1.9.5" \
     "pydantic==1.10.13" \
     "sentencepiece" \
     "tiktoken" \
     "einops" \
     "transformers_stream_generator" \
     "uvicorn" \
     "fastapi" \
     "yacs" \
     "setuptools_scm"
     # 安装 fschat（需要启用 PEP517 构建）
    pip install fschat--use-pep517
    ```

### 2.3 大语言模型下载

1. 切换至工作目录：

    ```
    cd /mnt/data
    ```

2. 下载对应大语言模型

    ```
    git clone +[目标模型网络地址]
    ```
   本项目中测试的模型地址：
   智谱chatglm3-6B：https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git
   百川Baichuan2-7B-Chat：https://www.modelscope.cn/baichuan-inc/Baichuan2-7B-Chat.git
   千问Qwen-7B-Chat：https://www.modelscope.cn/qwen/Qwen-7B-Chat.git

### 2.4 构建运行文件并运行

    在/mnt/workspace/目录下创建python源代码run_model.py

    ```python
    from transformers import TextStreamer, AutoTokenizer, AutoModelForCausalLM
    model_name = "/mnt/data/Baichuan2-7B-Chat"  # 本地路径，需要使用另一模型时只需修改此处路径即可
    prompt = ["请说出以下两句话区别在哪里？ 1、冬天：能穿多少穿多少 2、夏天：能穿多少穿多少","请说出以下两句话区别在哪里？单身狗产生的原因有两个，一是谁都看不上，二是谁都看不上","他知道我知道你知道他不知道吗？ 这句话里，到底谁不知道","明明明明明白白白喜欢他，可她就是不说。 这句话里，明明和白白谁喜欢谁？", "领导：你这是什么意思？ 小明：没什么意思。意思意思。 领导：你这就不够意思了。 小明：小意思，小意思。领导：你这人真有意思。 小明：其实也没有别的意思。 领导：那我就不好意思了。 小明：是我不好意思。请问：以上“意思”分别是什么意思。"]
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True
)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        trust_remote_code=True,
        torch_dtype="auto"  # 自动选择 float32/float16（根据模型配置）
).eval()
    for i in range(5):
        inputs = tokenizer(prompt[i], return_tensors="pt").input_ids
        streamer = TextStreamer(tokenizer)
        outputs = model.generate(inputs, streamer=streamer,
max_new_tokens=300)
        print("\n")
    ```

    启用一个终端，切换工作目录到python源程序所在的目录并运行

    ```
    cd /mnt/workspace
    python run_model.py
    ```    
   